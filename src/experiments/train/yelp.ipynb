{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bottom-anniversary",
   "metadata": {},
   "source": [
    "## Import packages and set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abstract-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,3\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "humanitarian-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller than the original GPT-2, only 6 layers (instead of 12), 12 heads, 768 dimensions (like GPT-2)\n",
    "model_name = \"gpt2-medium\" # \"gpt2-medium\" # distilgpt2 #gpt2-large it reachs the maximum gpu capacity\n",
    "experiment_name = \"yelp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-holocaust",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "included-yacht",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37344, 26)    review_count  useful_user  funny_user  cool_user      fans  average_stars  \\\n",
      "0     -0.436465    -0.214581   -0.159044  -0.167304 -0.232373       0.995970   \n",
      "1     -0.424311    -0.212954   -0.159044  -0.163708 -0.232373       1.116056   \n",
      "2      2.961771     3.285855    1.302974   2.933231  3.216466       0.549938   \n",
      "3     -0.300341    -0.204819   -0.155936  -0.161139 -0.162559       0.567093   \n",
      "4     -0.229848    -0.183668   -0.148168  -0.156001 -0.190484      -0.359283   \n",
      "\n",
      "   compliment_hot  compliment_more  compliment_profile  compliment_cute  ...  \\\n",
      "0       -0.119834        -0.088258           -0.039402        -0.066958  ...   \n",
      "1       -0.119834        -0.088258           -0.039402        -0.066958  ...   \n",
      "2        0.595663         0.908732            0.158631         0.079997  ...   \n",
      "3       -0.114110        -0.088258           -0.039402        -0.066958  ...   \n",
      "4       -0.114110        -0.088258           -0.039402        -0.066958  ...   \n",
      "\n",
      "   compliment_photos     stars  useful_review  funny_review  cool_review  \\\n",
      "0          -0.100955  0.882760      -0.526158     -0.309766    -0.385782   \n",
      "1          -0.100955  0.075290      -0.526158     -0.309766    -0.385782   \n",
      "2           1.576010 -1.539651      -0.059428     -0.309766    -0.385782   \n",
      "3          -0.100955  0.882760      -0.059428     -0.309766     0.405531   \n",
      "4          -0.092311  0.882760      -0.059428     -0.309766    -0.385782   \n",
      "\n",
      "                                                text  friend_count  \\\n",
      "0  New favorite, don't go at peak lunch though (t...     -0.404604   \n",
      "1  One of my fav Mexican spots in town! Very deli...     -0.409499   \n",
      "2  I've been trying to purchase cupcakes for week...      1.908428   \n",
      "3  This location is inside the 30th st station . ...      0.119194   \n",
      "4  Such a great bar. Clean and bright, friendly b...      1.147208   \n",
      "\n",
      "   elite_count  yelp_since_YRMO  yelp_since_year  \n",
      "0    -0.512150         0.628279         0.612600  \n",
      "1    -0.512150         1.019383         1.019548  \n",
      "2     2.597446         0.224953         0.205653  \n",
      "3    -0.512150         0.632353         0.612600  \n",
      "4    -0.512150        -1.400574        -1.422136  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"/hadatasets/fillipe.silva/LLMSegm/data/{experiment_name}/train.csv\")\n",
    "columns = df.columns.tolist()\n",
    "ds = Dataset.from_pandas(df)\n",
    "print(df.shape, df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4206fdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/37344 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 37344/37344 [00:09<00:00, 3848.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful_user is -0.2145809057776013, cool_review is -0.3857819574302367, useful_review is -0.5261577724615858, compliment_writer is -0.1322368124227246, compliment_funny is -0.1362365269175, compliment_more is -0.088257527134576, review_count is -0.4364647902773408, compliment_list is -0.0439897434822456, compliment_cool is -0.1362365269175, compliment_profile is -0.0394022516789422, compliment_note is -0.156450259749963, text is New favorite, don't go at peak lunch though (too crowded) Perfect brisket, great sides and sauce!, funny_review is -0.3097658360465847, compliment_hot is -0.1198341496823664, elite_count is -0.5121504816011141, compliment_cute is -0.0669580274633039, compliment_plain is -0.1225147908919149, yelp_since_YRMO is 0.6282788162521304, friend_count is -0.404603654155143, yelp_since_year is 0.6126004079611385, funny_user is -0.1590435484890861, stars is 0.8827599034766418, cool_user is -0.167303877508685, fans is -0.232373053979433, compliment_photos is -0.1009554008545602, average_stars is 0.9959702005617456, \n"
     ]
    }
   ],
   "source": [
    "def combine_data_ordered(sample):\n",
    "    concat = \"\"\n",
    "    for col in columns:\n",
    "        concat += \"%s is %s, \" % (col, str(sample[col]).strip())\n",
    "\n",
    "    return {\"concat\": concat}\n",
    "\n",
    "def combine_data_shuffled(sample):\n",
    "    concat = \"\"\n",
    "    for col in random.sample(columns, k=len(columns)):\n",
    "        concat += \"%s is %s, \" % (col, str(sample[col]).strip())\n",
    "\n",
    "    return {\"concat\": concat}\n",
    "\n",
    "# Shuffle the features or not\n",
    "shuffle = True \n",
    "if shuffle:\n",
    "    combined_ds = ds.map(combine_data_shuffled)\n",
    "else:\n",
    "    combined_ds = ds.map(combine_data_ordered)\n",
    "\n",
    "combined_ds = combined_ds.remove_columns(ds.column_names)\n",
    "print(combined_ds[\"concat\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-elephant",
   "metadata": {},
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liquid-practice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 37344/37344 [00:09<00:00, 4054.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "max_length = 125\n",
    "def tokenizer_function(sample):\n",
    "    result = tokenizer(sample[\"concat\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "# Tokenize dataset and create pytorch tensors\n",
    "tokenizer_ds = combined_ds.map(tokenizer_function, batched=True)\n",
    "tokenizer_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-second",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "harmful-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "epochs = 25\n",
    "batch_size = 4\n",
    "training_args = TrainingArguments(f\"/hadatasets/fillipe.silva/LLMSegm/models/{experiment_name}\", \n",
    "                                  num_train_epochs=epochs, \n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  save_steps=5000)\n",
    "trainer = Trainer(model, training_args, train_dataset=tokenizer_ds, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "organic-spice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77800' max='77800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77800/77800 10:09:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.980500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.926400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.867900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.880900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.882300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.826600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.803800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.801400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.807600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.725400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.736600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.734200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.690800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.683600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.622400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.637700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.637800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.637400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.592900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.589300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.587300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.591300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.546500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.550200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.546500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.514400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.516200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.516900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.482200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.493100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.468400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.462500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.468700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.466800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.453200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.442900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.444400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.413700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.390800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.390700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>0.390400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>0.377000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>0.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.380600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>0.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>0.370600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>0.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>0.362100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>0.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.365100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>0.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.356300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>0.354900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.358600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>0.358100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.360400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>0.352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>0.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>0.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>0.346200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.346800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>0.349600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>0.341600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>0.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.344700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>0.345900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.339800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>0.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.340500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>0.337500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>0.339600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.339300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/fillipe.silva/miniconda3/envs/llmsegm/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=77800, training_loss=0.5097872004962519, metrics={'train_runtime': 36595.6496, 'train_samples_per_second': 25.511, 'train_steps_per_second': 2.126, 'total_flos': 2.116784590848e+17, 'train_loss': 0.5097872004962519, 'epoch': 25.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() # resume_from_checkpoint = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-boston",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ordinary-freight",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = model_name + \"_\" + str(epochs) + \".pt\"\n",
    "model_path = f\"/hadatasets/fillipe.silva/LLMSegm/models/{experiment_name}/{model_name}\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-banner",
   "metadata": {},
   "source": [
    "### Look at loss curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-monthly",
   "metadata": {},
   "source": [
    "The trainer.state.log_history contains some information about the training.\n",
    "Just saving the loss curve, but one could also save the whole state of the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mature-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba2e86bc20>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rounds = len(trainer.state.log_history) - 1\n",
    "loss = [x[\"loss\"] if i < rounds else None for i, x in enumerate(trainer.state.log_history)]\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03450d8c",
   "metadata": {},
   "source": [
    "## Getting Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "changing-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(f\"/hadatasets/fillipe.silva/LLMSegm/data/{experiment_name}/test.csv\")\n",
    "columns = val_df.columns.tolist()\n",
    "ds = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b317aecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9336/9336 [00:02<00:00, 3416.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"cool_review is -0.3857819574302367, cool_user is -0.13596458092566, review_count is -0.2857561731506774, compliment_profile is -0.0213992701818918, compliment_more is -0.0095478482571435, text is I've never been inside I have only ordered ice cream in the drive thru. It has been 2 years of going and they have not messed up my order. The only issue is that when its busy during the summer if the line is long I won't order a banana split. The reason is they make it right away sometimes and its already starting to melt by the time I get it. And by the time I get home its already soup. I only line 2 miles down the street., fans is -0.1765214126506289, yelp_since_YRMO is 1.4064131223699734, stars is -0.7321808614982132, funny_user is -0.1497214395035361, compliment_cool is -0.0719265294452116, elite_count is 0.1788710190731522, compliment_funny is -0.0719265294452116, useful_user is -0.1783807162281949, useful_review is -0.5261577724615858, compliment_note is -0.0845846983526729, friend_count is -0.3434123281751691, compliment_writer is -0.0682278934384166, compliment_list is -0.0439897434822456, average_stars is 0.6871783835629638, compliment_hot is -0.0912142574462444, funny_review is -0.3097658360465847, yelp_since_year is 1.4264950157205585, compliment_cute is -0.0669580274633039, compliment_plain is -0.1041069403915909, compliment_photos is -0.0490904785653145, \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_data_ordered(sample):\n",
    "    concat = \"\"\n",
    "    for col in columns:\n",
    "        concat += \"%s is %s, \" % (col, str(sample[col]).strip())\n",
    "\n",
    "    return {\"concat\": concat}\n",
    "\n",
    "def combine_data_shuffled(sample):\n",
    "    concat = \"\"\n",
    "    for col in random.sample(columns, k=len(columns)):\n",
    "        concat += \"%s is %s, \" % (col, str(sample[col]).strip())\n",
    "\n",
    "    return {\"concat\": concat}\n",
    "\n",
    "combined_ds = ds.map(combine_data_shuffled)\n",
    "combined_ds[\"concat\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b86e0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'other option to do embds (not tested)\\ntoken_ids = tokenizer.encode(\"Your input text goes here\", add_special_tokens=False)\\n\\n# Convert token IDs to tensor and move it to the model\\'s device\\ntokens_tensor = torch.tensor([token_ids], device=model.device)\\nwith torch.no_grad():\\n# Forward pass through the model\\noutputs = model(tokens_tensor)\\n# Retrieve the hidden states from the model output\\nhidden_states = outputs[0]  # \\'outputs\\' is a tuple, the first element is the hidden states\\n\\n# Averaging over the sequence length\\nprint(len((hidden_states[0].mean(dim=0))), (hidden_states[0].mean(dim=0)))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "embs = []\n",
    "for text in combined_ds[\"concat\"]:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Extract logits\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Use logits as text embeddings\n",
    "    text_embedding = logits[:, -1, :]  # Take the last token's logits as the embedding\n",
    "\n",
    "    # Convert tensor to numpy array if needed\n",
    "    text_embedding_np = text_embedding.detach().cpu().numpy()\n",
    "\n",
    "    embs.append(text_embedding_np[0])\n",
    "\n",
    "'''other option to do embds (not tested)\n",
    "token_ids = tokenizer.encode(\"Your input text goes here\", add_special_tokens=False)\n",
    "\n",
    "# Convert token IDs to tensor and move it to the model's device\n",
    "tokens_tensor = torch.tensor([token_ids], device=model.device)\n",
    "with torch.no_grad():\n",
    "# Forward pass through the model\n",
    "outputs = model(tokens_tensor)\n",
    "# Retrieve the hidden states from the model output\n",
    "hidden_states = outputs[0]  # 'outputs' is a tuple, the first element is the hidden states\n",
    "\n",
    "# Averaging over the sequence length\n",
    "print(len((hidden_states[0].mean(dim=0))), (hidden_states[0].mean(dim=0)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcffa6",
   "metadata": {},
   "source": [
    "#### Saving embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "442bc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.DataFrame(embs)\n",
    "embedding_df.to_csv(f'/hadatasets/fillipe.silva/LLMSegm/data/{experiment_name}/{model_name.replace(\".pt\",\"\")}_test_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
