{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing clustering stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dependencies and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import dirname, abspath, join, exists\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "#from rpy2.rinterface_lib.embedded import RRuntimeError\n",
    "#import rpy2.robjects as ro\n",
    "#from rpy2.robjects.packages import importr\n",
    "#from rpy2.robjects.conversion import localconverter\n",
    "#from rpy2.robjects import pandas2ri\n",
    "#pandas2ri.activate()\n",
    "\n",
    "#clue = importr(\"clue\")\n",
    "#bootcluster = importr(\"bootcluster\")\n",
    "#OTclust = importr(\"OTclust\")\n",
    "\n",
    "#from config.definitions import ROOT_DIR\n",
    "#os.chdir(ROOT_DIR + '\\\\src\\\\model\\\\')\n",
    "\n",
    "from compute_stability_exp_args import ComputerStabilityArguments\n",
    "\n",
    "rng = np.random.RandomState(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering stability methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stability:\n",
    "\n",
    "    \"\"\"\n",
    "    Class to compute stability using CPU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stability_args):\n",
    "        self.stability_args = stability_args\n",
    "\n",
    "    def run(self, \n",
    "            data, \n",
    "    ):\n",
    "        \"\"\"\n",
    "            param: data\n",
    "            size_sample: size_sample\n",
    "        \"\"\"\n",
    "        data = data \n",
    "        size_sample = data.shape[0]\n",
    "        clusters = self.stability_args.clusters\n",
    "        num_bootstrap_samples = self.stability_args.num_bootstrap_samples\n",
    "        num_train_epochs = self.stability_args.num_train_epochs\n",
    "        path_and_file_name_to_save = self.stability_args.output_dir +  self.stability_args.output_stab_name\n",
    "        project_name = self.stability_args.project_name\n",
    "        random_state = self.stability_args.RNDN\n",
    "        \n",
    "        manager = Manager()\n",
    "        stab_methods = manager.dict()\n",
    "        stab_methods[\"adjusted_rand_score\"] = manager.list()\n",
    "        stab_methods[\"adjusted_mutual_info_score\"] = manager.list()\n",
    "        stab_methods[\"bagclust\"] = manager.list()\n",
    "        stab_methods[\"han\"] = manager.list()\n",
    "        stab_methods[\"OTclust\"] = manager.list()\n",
    "\n",
    "        arguments = {\n",
    "            \"clusters\": clusters, \n",
    "            \"num_train_epochs\": num_train_epochs,\n",
    "            \"num_bootstrap_samples\": num_bootstrap_samples,\n",
    "            \"random_state\": random_state\n",
    "        }\n",
    "        stab_epochs = {}\n",
    "\n",
    "        rData = None\n",
    "        #with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        #    rData = ro.conversion.rpy2py(data)\n",
    "        for ep in tqdm(range(num_train_epochs)):\n",
    "            for cluster in clusters:\n",
    "\n",
    "                kmeans = KMeans(n_clusters=cluster, n_init=10)\n",
    "                labels, indices = self.get_labels_and_indices(data, kmeans, size_sample, num_bootstrap_samples, random_state)    \n",
    "\n",
    "                if self.stability_args.adjusted_rand_score: self.adjusted_rand_score(labels, indices, cluster, stab_methods)\n",
    "                if self.stability_args.adjusted_mutual_info_score: self.adjusted_mutual_info_score(labels, indices, cluster, stab_methods)\n",
    "                if self.stability_args.bagclust: self.bagclust(rData, num_bootstrap_samples, cluster, stab_methods)\n",
    "                if self.stability_args.han: self.han(rData, num_bootstrap_samples, cluster, stab_methods)\n",
    "                if self.stability_args.OTstab: self.OTstab(rData, num_bootstrap_samples, cluster, stab_methods)\n",
    "\n",
    "            \n",
    "            #To JSON serialize \n",
    "            stab_methods = dict(stab_methods)\n",
    "            for k in stab_methods.keys():\n",
    "                stab_methods[k] = list(stab_methods[k])\n",
    "        \n",
    "            stab_epochs[ep] = stab_methods            \n",
    "            stab_methods = manager.dict()\n",
    "            stab_methods[\"adjusted_rand_score\"] = manager.list()\n",
    "            stab_methods[\"adjusted_mutual_info_score\"] = manager.list()\n",
    "            stab_methods[\"bagclust\"] = manager.list()\n",
    "            stab_methods[\"han\"] = manager.list()\n",
    "            stab_methods[\"OTclust\"] = manager.list()\n",
    "        print(stab_epochs)   \n",
    "        self.save(stab_epochs, arguments, path_and_file_name_to_save)\n",
    "\n",
    "    def get_labels_and_indices(self, data, clrt_algorithm, size_sample, num_bootstrap_samples, random_state):\n",
    "        labels = []\n",
    "        indices = []\n",
    "        for _ in range(num_bootstrap_samples):\n",
    "            # draw bootstrap samples, store indices\n",
    "            sample_indices = rng.randint(0, data.shape[0], size_sample)\n",
    "            indices.append(sample_indices)\n",
    "            clrt_algorithm = clone(clrt_algorithm)\n",
    "            if hasattr(clrt_algorithm, \"random_state\"):\n",
    "                # randomize estimator if possible\n",
    "                clrt_algorithm.random_state = rng.randint(1e5)\n",
    "            data_bootstrap = data[sample_indices]\n",
    "            clrt_algorithm.fit(data_bootstrap)\n",
    "            # store clustering outcome using original indices\n",
    "            relabel = -np.ones(data.shape[0], dtype=int)\n",
    "            relabel[sample_indices] = clrt_algorithm.labels_\n",
    "            labels.append(relabel)\n",
    "        return (labels, indices)\n",
    "\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\n",
    "    def adjusted_rand_score(self, labels, indices, cluster, stab_methods):\n",
    "        scores = []\n",
    "        for l, i in zip(labels, indices):\n",
    "            for k, j in zip(labels, indices):\n",
    "                in_both = np.intersect1d(i, j)\n",
    "                scores.append(adjusted_rand_score(l[in_both], k[in_both])) \n",
    "        stab_methods['adjusted_rand_score'].append(np.mean(scores))\n",
    "\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html\n",
    "    def adjusted_mutual_info_score(self, labels, indices, cluster, stab_methods):\n",
    "        scores = []\n",
    "        for l, i in zip(labels, indices):\n",
    "            for k, j in zip(labels, indices):\n",
    "                in_both = np.intersect1d(i, j)\n",
    "                scores.append(adjusted_mutual_info_score(l[in_both], k[in_both]))\n",
    "        stab_methods['adjusted_mutual_info_score'].append(np.mean(scores))\n",
    "\n",
    "    #\"A prediction-based resampling method for estimating the number of clusters in a dataset.\"\n",
    "    #\"Bagging to improve the accuracy of a clustering procedure.\"\n",
    "    #Explicação: Stability estimation for unsupervised clustering: A review\n",
    "    def bagclust(self, rData, num_bootstrap_samples, n_cluster, stab_methods):\n",
    "        rDataStab = clue.cl_bag(x = rData, B = num_bootstrap_samples, k = n_cluster)\n",
    "        stab_methods['bagclust'].append(rDataStab.rx2['.Data'].max(axis = 1).mean())\n",
    "\n",
    "    #Bootstrapping estimates of stability for clusters,observations and model selection\n",
    "    #Para entender vá para a página 4 Seção 2 Fig. 1.\n",
    "    def han(self, rData, num_bootstrap_samples, n_cluster, stab_methods):\n",
    "        try:\n",
    "            hanStab = bootcluster.stability(x = rData, k = n_cluster, B = num_bootstrap_samples)\n",
    "            stab_overall = float(0) if math.isnan(float(hanStab.rx2['overall'])) else float(hanStab.rx2['overall'])\n",
    "            stab_methods['han'].append(stab_overall)\n",
    "        except RRuntimeError:\n",
    "            stab_methods['han'].append(float(0))\n",
    "\n",
    "    #CPS Analysis for cluster validation\n",
    "    #Install from github https://github.com/cran/OTclust\n",
    "    #Melhor explicação: Denoising Methods for Inferring Microbiome Community Content and Abundance\n",
    "    def OTstab(self, rData, num_bootstrap_samples, n_cluster,stab_methods): \n",
    "        otclust = OTclust.clustCPS(rData, k=n_cluster, l= False, pre=False, noi=\"after\",\n",
    "                 nPCA = 2, nEXP = num_bootstrap_samples)\n",
    "        stab_methods['OTclust'].append(float(otclust.rx2['tight_all']))\n",
    "\n",
    "    def save(self, stab_epochs, arguments, path_and_file_name_to_save):\n",
    "        data = json.dumps([stab_epochs, arguments], indent = 4)\n",
    "        i = 1\n",
    "        path_and_file_name_to_save = path_and_file_name_to_save.replace(\".json\", \"\")\n",
    "        while os.path.exists(f\"{path_and_file_name_to_save}-{i}.json\"):\n",
    "            i += 1\n",
    "        file = open(f\"{path_and_file_name_to_save}-{i}.json\",\"w\")\n",
    "        file.write(data)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_args = ComputerStabilityArguments(\n",
    "    project_name='Stability - SERIEMA',\n",
    "    data_path='/hadatasets/fillipe.silva/LLMSegm/data/yelp/gpt2-medium_25_test_embeddings.csv',\n",
    "    output_dir='/hadatasets/fillipe.silva/LLMSegm/data/yelp/',\n",
    "    output_stab_name='stability.json', \n",
    "    clusters=[2], \n",
    "    num_train_epochs=1, \n",
    "    num_bootstrap_samples=5,\n",
    "    num_random_samples=0, \n",
    "    repeat_experimet=1, \n",
    "    output_log_name='stability.json', \n",
    "    mode='CPU', \n",
    "    adjusted_rand_score=True, \n",
    "    adjusted_mutual_info_score=True, \n",
    "    bagclust=False, \n",
    "    han=False, \n",
    "    OTstab=False, \n",
    "    RNDN=1, \n",
    "    report_to=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:38<00:00, 158.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'adjusted_rand_score': [0.9659552926148248], 'adjusted_mutual_info_score': [0.9410173995499824], 'bagclust': [], 'han': [], 'OTclust': []}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not exists(stability_args.output_dir):\n",
    "    makedirs(stability_args.output_dir)\n",
    "\n",
    "st = time.time()\n",
    "for i in range(1, stability_args.repeat_experimet + 1):\n",
    "    data = pd.read_csv(stability_args.data_path, skiprows = 0)\n",
    "    if stability_args.num_random_samples:\n",
    "        data = data.sample(n=stability_args.num_random_samples, replace = True)\n",
    "    data = data.to_numpy()\n",
    "\n",
    "    stabO = Stability(stability_args)\n",
    "    stabO.run(data)\n",
    "\n",
    "et = time.time()\n",
    "elapsed_time = et - st"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer-segmentation-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
